# mistral-agriculture-finetuning
# Mistral Fine-Tuning for Indian Agriculture Dataset

This repository contains the code and resources for fine-tuning the open-source **Mistral** large language model using an Indian agriculture dataset sourced from [Kaggle](https://www.kaggle.com). The project aims to adapt the capabilities of Mistral to address tasks related to the agriculture domain in the Indian context.

## Project Overview

Fine-tuning a large language model like Mistral with a domain-specific dataset enhances its ability to generate relevant and accurate responses. This repository includes:
- The fine-tuning script in a Jupyter Notebook (`AGmistralfinetuning.ipynb`)
- Guidance for setting up the environment
- Instructions for running the fine-tuning process

## Dataset

The [dataset](https://www.kaggle.com/datasets/vineetkukreti/indian-agriculture-dataset) used for fine-tuning is from Kaggle and is focused on Indian agriculture. It includes information of dstrict-wise yearly area, yield and production.


### Prerequisites

Ensure the following tools and dependencies are installed:

- Python 3.8 or higher
- PyTorch (for model training)
- Hugging Face Transformers library
- Jupyter Notebook


=
